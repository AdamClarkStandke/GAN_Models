{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepConvolutionalGan(DCGAN).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOa2p/1LvZ2D+U5QcZlr7/D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aCStandke/GAN_Models/blob/main/DeepConvolutionalGan(DCGAN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Convolutional GAN (DCGAN)\n",
        "\n",
        "Implementation of the Deep Convolutional GAN as detailed in Unsurpervised Representation Learning with Deep Convolutional Generative Adversaial Networks, [DCGAN](https://arxiv.rg/abs/15511.06434) and detailed in page 196 of the book Advanced Deep Learning with Python \n",
        "\n"
      ],
      "metadata": {
        "id": "3yfjd1u52iJU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gs22OI-P18CV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Dropout, Input, Dense, Reshape, Flatten\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import adam_v2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator\n"
      ],
      "metadata": {
        "id": "DO3VDbykG7zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function that builds the generator\n",
        "def build_generator(latent_input):\n",
        "  model = Sequential([\n",
        "                      # first fully connected layer to take in 1D latent vector of the generator \n",
        "                      Dense(7*7*256, use_bias=False, input_shape=latent_input.shape[1:]),\n",
        "                      # applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.\n",
        "                      BatchNormalization(), \n",
        "                      LeakyReLU(), \n",
        "                      Reshape((7, 7, 256)),\n",
        "                      # first layer of upsampeling(i.e. deconvolution) of the 1D latent vector/input  \n",
        "                      Conv2DTranspose(filters=128, kernel_size=(5,5), strides=(1,1), padding='same', use_bias=False), \n",
        "                      BatchNormalization(), \n",
        "                      LeakyReLU(), \n",
        "                      # second layer of upsampeling(i.e. deconvolution) in which the volume depth is reduced\n",
        "                      Conv2DTranspose(filters=64, kernel_size=(5,5), strides=(2,2), padding='same', use_bias=False), \n",
        "                      BatchNormalization(), \n",
        "                      LeakyReLU(), \n",
        "                      # third layer upsampeling(i.e. deconvolution) in which the volume depth is reduced\n",
        "                      Conv2DTranspose(filters=1, kernel_size=(5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh'), \n",
        "\n",
        "  ])\n",
        "\n",
        "  # forward propogation of model\n",
        "  generated = model(latent_input)\n",
        "  return Model(z, generated)"
      ],
      "metadata": {
        "id": "ymvL5uTZG5FT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator"
      ],
      "metadata": {
        "id": "QOalxX9NfxtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "  model = Sequential([\n",
        "                     # first layers of discriminator network\n",
        "                     Conv2D(filters=64, kernel_size=(5, 5), strides=(2,2), padding='same', input_shape = (28, 28, 1)),\n",
        "                     LeakyReLU(),\n",
        "                     Dropout(0.3), \n",
        "                     # second layers of discriminator network\n",
        "                     Conv2D(filters=128, kernel_size=(5, 5), strides=(2,2), padding='same'),\n",
        "                     LeakyReLU(),\n",
        "                     Dropout(0.3),\n",
        "                     Flatten(), \n",
        "                     Dense(1, activation='sigmoid'),                   \n",
        "                    ])\n",
        "  image = Input(shape=(28, 28, 1))\n",
        "  output = model(image)\n",
        "  return Model(image, output)"
      ],
      "metadata": {
        "id": "9fY-P644fwwe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Function"
      ],
      "metadata": {
        "id": "NMrS-ueUqYoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(generator, discriminator, combined, steps, batch_size):\n",
        "  # loading the dataset\n",
        "  (x_train, _), _ = fashion_mnist.load_data()\n",
        "  # Rescale in [-1,1] interval\n",
        "  x_train = (x_train.astype(np.float32)-127.5)/127.5\n",
        "  x_train = np.expand_dims(x_train, axis=-1)\n",
        "  # Discriminator ground truths for real and fake images\n",
        "  real = np.ones((batch_size, 1))\n",
        "  fake = np.zeros((batch_size, 1))\n",
        "\n",
        "  latent_dim = generator.input_shape[1]\n",
        "\n",
        "  for step in range(steps):\n",
        "    # first train the discriminator\n",
        "\n",
        "      # select a random batch of real images from the uninform distribution\n",
        "      real_images = x_train[np.random.randint(0, x_train.shape[0], batch_size)]\n",
        "\n",
        "      # generate a random batch of noise from the normal distribution for the generator \n",
        "      noise = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
        "\n",
        "      # generate a bath of new images using the generator\n",
        "      generated_images = generator.predict(noise)\n",
        "\n",
        "      # discriminator loss on real images\n",
        "      discriminator_real_loss = discriminator.train_on_batch(real_images, real)\n",
        "      # discriminator loss on fake images\n",
        "      discriminator_fake_loss = discriminator.train_on_batch(generated_images, fake)\n",
        "      # discriminator total loss\n",
        "      discriminator_loss = 0.5 * np.add(discriminator_real_loss, discriminator_fake_loss)\n",
        "\n",
        "    # Second train the generator\n",
        "\n",
        "      # generate latent vector z from the normal distribution\n",
        "      noise = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
        "      # generator loss: As noted in the book the real images are combined with the latent vector to maximize the discriminator loss\n",
        "      generator_loss = combined.train_on_batch(noise, real)\n",
        "\n",
        "      # Display progress\n",
        "      print(f\"Step: {step} [Discriminator loss:{discriminator_loss[0]} acc:{100*discriminator_loss[1]}] [Generator loss:{generator_loss}]\")\n",
        "      "
      ],
      "metadata": {
        "id": "M3iBRkbtqVq9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}